{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies_dev = pd.read_excel('Dev_Set/dev_set_groundtruth_and_trailers.xls',usecols=['movie','goodforairplane','filename'],index_col='filename')\n",
    "movies_test = pd.read_csv('Test_set/test_set_labels.csv',names=['movie','filename','goodforairplane'],header=None, skiprows=1,index_col='filename',sep=';',dtype={'goodforairplane':int})\n",
    "movies_test.sort_index(inplace=True)\n",
    "\n",
    "movies = movies_dev.append(movies_test, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.cElementTree as et\n",
    "\n",
    "for filename in os.listdir('Dev_Set/XML'):\n",
    "    tree = et.parse('Dev_Set/XML/'+filename)\n",
    "    root = tree.getroot()\n",
    "    tmp = root[0]\n",
    "    \n",
    "    for i in tmp.attrib:\n",
    "        movies.loc[filename[:-4],i] = tmp.get(i)\n",
    "\n",
    "for filename in os.listdir('Test_Set/XML'):\n",
    "    tree = et.parse('Test_Set/XML/'+filename)\n",
    "    root = tree.getroot()\n",
    "    tmp = root[0]\n",
    "    for i in tmp.attrib:\n",
    "        movies.loc[filename[:-4],i] = tmp.get(i)\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "visuals = pd.DataFrame()\n",
    "names = []\n",
    "for file in os.listdir(\"Dev_Set/vis_descriptors\"):\n",
    "    data = pd.read_csv(os.path.join(r\"Dev_Set/vis_descriptors\",file),header=None)\n",
    "    name = file.split('.')\n",
    "    name = name[0]\n",
    "    names.append(name)\n",
    "    data = data.mean(axis=0)\n",
    "    data = data.transpose()\n",
    "    visuals = visuals.append(data,ignore_index=True)\n",
    "    \n",
    "for file in os.listdir(\"Test_Set/vis_descriptors\"):\n",
    "    data = pd.read_csv(os.path.join(r\"Test_Set/vis_descriptors\",file),header=None)\n",
    "    name = file.split('.')\n",
    "    name = name[0]\n",
    "    names.append(name)\n",
    "    data = data.mean(axis=0)\n",
    "    data = data.transpose()\n",
    "    visuals = visuals.append(data,ignore_index=True)\n",
    "    \n",
    "visuals.insert(0,'filename',names)\n",
    "visuals.set_index('filename',inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "audio = pd.DataFrame()\n",
    "names_train = []\n",
    "names = []\n",
    "\n",
    "for file in os.listdir(\"Dev_Set/audio_descriptors\"):\n",
    "    data = pd.read_csv(os.path.join(r\"Dev_Set/audio_descriptors\",file),header=None)\n",
    "    name = file.split('.')\n",
    "    name = name[0]\n",
    "    names_train.append(name)\n",
    "    names.append(name)\n",
    "    data = data.mean(axis=1)\n",
    "    audio = audio.append(data,ignore_index=True)\n",
    " \n",
    "names_test = []\n",
    "\n",
    "for file in os.listdir(\"Test_Set/audio_descriptors\"):\n",
    "    data = pd.read_csv(os.path.join(r\"Test_Set/audio_descriptors\",file),header=None)\n",
    "    name = file.split('.')\n",
    "    name = name[0]\n",
    "    names_test.append(name)\n",
    "    names.append(name)\n",
    "    data = data.mean(axis=1)\n",
    "    audio = audio.append(data,ignore_index=True)\n",
    "    \n",
    "audio.insert(0,'filename',names)\n",
    "audio.set_index('filename',inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_text_train = pd.read_csv('Dev_Set/text_descriptors/tdf_idf_dev.csv',header=0)\n",
    "\n",
    "data_text_train.insert(0,'filename',names_train)\n",
    "data_text_train.set_index('filename',inplace=True)\n",
    "\n",
    "data_text_test = pd.read_csv('Test_Set/text_descriptors/tdf_idf_test.csv',header=0)\n",
    "\n",
    "data_text_test.insert(0,'filename',names_test)\n",
    "data_text_test.set_index('filename',inplace=True)\n",
    "\n",
    "text = pd.concat([data_text_train,data_text_test], sort=False)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "movies.drop(['released','Website','imdbID','poster','tomatoConsensus','writer','DVD','plot','title','awards'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "movies = movies.replace('N/A','NaN')\n",
    "movies['imdbRating'] = movies['imdbRating'].astype(np.float)\n",
    "movies['imdbVotes'] = movies['imdbVotes'].replace('[,]','',regex=True).astype(float)\n",
    "movies['runtime'] = movies['runtime'].replace('[\\smin]','',regex=True).astype(float)\n",
    "movies['rated'] = movies['rated'].replace('NaN','NOT RATED')\n",
    "movies['year'] = movies['year'].astype(float)\n",
    "movies['metascore'] = movies['metascore'].astype(float)\n",
    "movies['tomatoRating'] = movies['tomatoRating'].astype(float)\n",
    "movies['tomatoUserRating'] = movies['tomatoUserRating'].astype(float)\n",
    "movies['tomatoMeter'] = movies['tomatoMeter'].astype(float)\n",
    "movies['tomatoUserMeter'] = movies['tomatoUserMeter'].astype(float)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "movies.fillna(0,inplace=True)\n",
    "visuals.fillna(0,inplace=True)\n",
    "audio.fillna(0,inplace=True)\n",
    "text.fillna(0,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "metadata = movies[['language','year','genre','country','runtime','rated']]\n",
    "userrating = movies[['imdbRating','metascore','tomatoRating','tomatoUserRating','tomatoMeter','tomatoUserMeter']]\n",
    "meta_and_user = movies[['language','year','genre','country','runtime','rated','imdbRating','metascore','tomatoRating',\n",
    "                       'tomatoUserRating','tomatoMeter','tomatoUserMeter']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import Encoding as enc\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    enc.one_hot_encode(metadata,'language',True)\n",
    "    enc.one_hot_encode(metadata,'genre',True)\n",
    "    enc.one_hot_encode(metadata, 'country',True)\n",
    "    enc.one_hot_encode(metadata, 'rated',True)\n",
    "\n",
    "metadata.drop(['language','country','rated','genre'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    enc.one_hot_encode(meta_and_user,'language',True)\n",
    "    enc.one_hot_encode(meta_and_user, 'country',True)\n",
    "    enc.one_hot_encode(meta_and_user, 'genre',True)\n",
    "    enc.one_hot_encode(meta_and_user, 'rated',True)\n",
    "\n",
    "meta_and_user.drop(['language','country','rated','genre'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski',\n",
    "                           metric_params=None,n_jobs=-1)\n",
    "nc = NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
    "tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                              min_weight_fraction_leaf=0.0, max_features=None, random_state=0, max_leaf_nodes=None,\n",
    "                              class_weight=None, presort=False)\n",
    "log = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1,\n",
    "                         class_weight=None, random_state=0, solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "svm = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "          cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=0)\n",
    "bag = BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "                        bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=-1, random_state=0, verbose=0)\n",
    "rf = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, \n",
    "                            oob_score=False, n_jobs=-1, random_state=0, verbose=0, warm_start=False, class_weight=None)\n",
    "ada = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=0)\n",
    "gb = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, random_state=0,\n",
    "                                max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "gauss = GaussianNB()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier\n",
      "Precision: 0.5956349206349205, Recall: 0.6366666666666666, f1: 0.5642607392607393\n",
      "\n",
      "NearestCentroid\n",
      "Precision: 0.5595238095238094, Recall: 0.5366666666666666, f1: 0.5382478632478632\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Precision: 0.48797619047619045, Recall: 0.6, f1: 0.524155844155844\n",
      "\n",
      "LogisticRegression\n",
      "Precision: 0.5125, Recall: 0.56, f1: 0.5244599844599845\n",
      "\n",
      "SVC\n",
      "Precision: 0.5000396825396825, Recall: 0.6766666666666667, f1: 0.5602319902319903\n",
      "\n",
      "BaggingClassifier\n",
      "Precision: 0.5275, Recall: 0.45, f1: 0.44353646353646353\n",
      "\n",
      "RandomForestClassifier\n",
      "Precision: 0.4911904761904761, Recall: 0.40666666666666673, f1: 0.4181401931401932\n",
      "\n",
      "AdaBoostClassifier\n",
      "Precision: 0.5201587301587302, Recall: 0.5233333333333333, f1: 0.4955694305694306\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Precision: 0.4552777777777778, Recall: 0.5033333333333334, f1: 0.46497502497502496\n",
      "\n",
      "GaussianNB\n",
      "Precision: 0.45, Recall: 0.13333333333333336, f1: 0.19523809523809527\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "algo_pool = [knn,nc,tree,log,svm,bag,rf,ada,gb,gauss]\n",
    "\n",
    "for i in algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=metadata[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=metadata[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=metadata[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier\n",
      "Precision: 0.6058333333333332, Recall: 0.6566666666666665, f1: 0.6193706293706293\n",
      "\n",
      "NearestCentroid\n",
      "Precision: 0.5913095238095238, Recall: 0.6133333333333334, f1: 0.5925019425019424\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Precision: 0.48154761904761906, Recall: 0.48999999999999994, f1: 0.4686790986790987\n",
      "\n",
      "LogisticRegression\n",
      "Precision: 0.5650793650793652, Recall: 0.5833333333333334, f1: 0.5491286491286491\n",
      "\n",
      "SVC\n",
      "Precision: 0.5140873015873015, Recall: 0.73, f1: 0.6006327006327006\n",
      "\n",
      "BaggingClassifier\n",
      "Precision: 0.475, Recall: 0.44666666666666666, f1: 0.44631313131313133\n",
      "\n",
      "RandomForestClassifier\n",
      "Precision: 0.5504761904761903, Recall: 0.5433333333333332, f1: 0.5259090909090909\n",
      "\n",
      "AdaBoostClassifier\n",
      "Precision: 0.4796428571428571, Recall: 0.45, f1: 0.447921522921523\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Precision: 0.505, Recall: 0.5299999999999999, f1: 0.498962703962704\n",
      "\n",
      "GaussianNB\n",
      "Precision: 0.5, Recall: 0.17, f1: 0.23968253968253966\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=meta_and_user[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=meta_and_user[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=meta_and_user[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier\n",
      "Precision: 0.4938095238095238, Recall: 0.6566666666666665, f1: 0.47232323232323237\n",
      "\n",
      "NearestCentroid\n",
      "Precision: 0.6583333333333333, Recall: 0.6133333333333334, f1: 0.42976190476190473\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Precision: 0.5288095238095238, Recall: 0.48999999999999994, f1: 0.5272150072150072\n",
      "\n",
      "LogisticRegression\n",
      "Precision: 0.549047619047619, Recall: 0.5833333333333334, f1: 0.5850738150738151\n",
      "\n",
      "SVC\n",
      "Precision: 0.5569444444444445, Recall: 0.73, f1: 0.7085714285714285\n",
      "\n",
      "BaggingClassifier\n",
      "Precision: 0.5166666666666667, Recall: 0.44666666666666666, f1: 0.47478354978354986\n",
      "\n",
      "RandomForestClassifier\n",
      "Precision: 0.5401190476190475, Recall: 0.5433333333333332, f1: 0.51509324009324\n",
      "\n",
      "AdaBoostClassifier\n",
      "Precision: 0.4826190476190476, Recall: 0.45, f1: 0.4621950271950272\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Precision: 0.5351984126984127, Recall: 0.5299999999999999, f1: 0.5832234432234432\n",
      "\n",
      "GaussianNB\n",
      "Precision: 0.575, Recall: 0.17, f1: 0.3268398268398268\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=visuals[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=visuals[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=meta_and_user[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier\n",
      "Precision: 0.47214285714285714, Recall: 0.49333333333333346, f1: 0.4702974802974803\n",
      "\n",
      "NearestCentroid\n",
      "Precision: 0.5933333333333334, Recall: 0.24333333333333335, f1: 0.33430735930735933\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Precision: 0.45999999999999996, Recall: 0.42333333333333334, f1: 0.43787878787878787\n",
      "\n",
      "LogisticRegression\n",
      "Precision: 0.4978571428571429, Recall: 0.5633333333333332, f1: 0.5227505827505826\n",
      "\n",
      "SVC\n",
      "Precision: 0.4773015873015873, Recall: 0.69, f1: 0.5608458208458209\n",
      "\n",
      "BaggingClassifier\n",
      "Precision: 0.3966666666666666, Recall: 0.33, f1: 0.3508080808080808\n",
      "\n",
      "RandomForestClassifier\n",
      "Precision: 0.5333333333333333, Recall: 0.4166666666666667, f1: 0.43199134199134204\n",
      "\n",
      "AdaBoostClassifier\n",
      "Precision: 0.5069047619047619, Recall: 0.47333333333333333, f1: 0.48033799533799526\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Precision: 0.5214285714285714, Recall: 0.5166666666666667, f1: 0.5157109557109556\n",
      "\n",
      "GaussianNB\n",
      "Precision: 0.3738095238095238, Recall: 0.33333333333333337, f1: 0.3504273504273504\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=audio[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=audio[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=audio[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier\n",
      "Precision: 0.5477777777777778, Recall: 1.0, f1: 0.7071428571428571\n",
      "\n",
      "NearestCentroid\n",
      "Precision: 0.5382539682539683, Recall: 0.9400000000000001, f1: 0.6826007326007326\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Precision: 0.4882142857142857, Recall: 0.4666666666666667, f1: 0.4441308691308691\n",
      "\n",
      "LogisticRegression\n",
      "Precision: 0.5477777777777778, Recall: 1.0, f1: 0.7071428571428571\n",
      "\n",
      "SVC\n",
      "Precision: 0.5477777777777778, Recall: 1.0, f1: 0.7071428571428571\n",
      "\n",
      "BaggingClassifier\n",
      "Precision: 0.42480158730158735, Recall: 0.6133333333333333, f1: 0.4945787545787546\n",
      "\n",
      "RandomForestClassifier\n",
      "Precision: 0.3388095238095238, Recall: 0.42000000000000004, f1: 0.36505827505827504\n",
      "\n",
      "AdaBoostClassifier\n",
      "Precision: 0.5671428571428571, Recall: 0.4666666666666667, f1: 0.49787878787878787\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Precision: 0.4184523809523809, Recall: 0.56, f1: 0.47074092574092574\n",
      "\n",
      "GaussianNB\n",
      "Precision: 0.5349999999999999, Recall: 0.6033333333333334, f1: 0.539015429015429\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=text[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=text[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=text[0:95],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Index(['Latin', 'Music', 'Yiddish', 'Arabic', 'Russian', 'Turkish', 'Urdu',\n",
      "       'Cantonese', 'Inuktitut', 'Switzerland', 'Adventure',\n",
      "       'Egyptian (Ancient)', 'English', 'Horror', 'Swahili', 'Serbian',\n",
      "       'runtime', 'Portuguese', 'Panjabi', 'Mandarin',\n",
      "       'American Sign Language', 'Sign Languages', 'Sci-Fi', 'Musical',\n",
      "       'Drama', 'Pawnee', 'Swedish', 'Chinese', 'Mystery', 'Egypt', 'Thriller',\n",
      "       'German', 'Italian', 'Fantasy', 'Flemish', 'Comedy', 'Greek', 'Sioux',\n",
      "       'Documentary', 'Action', 'Dutch', 'Vietnamese', 'Family', 'Icelandic',\n",
      "       'Western', 'Crime', 'Mongolian', 'Swiss German', 'Hmong', 'Korean',\n",
      "       'Catalan', 'Hindi', 'French', 'Animation', 'Sport', 'Denmark',\n",
      "       'Bosnian', 'year', 'War', 'Biography', 'Romance', 'Croatian',\n",
      "       'Romanian', 'Hungarian', 'Danish', 'Algonquin', 'Bengali', 'Spanish',\n",
      "       'Japanese', 'History', 'Filipino', 'Navajo', 'Konkani',\n",
      "       'Scottish Gaelic'],\n",
      "      dtype='object')\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c5537b5d7008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLVW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmetadata_selected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLVW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlvw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'goodforairplane'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m74\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmeta_and_user_selected_fetures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLVW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlvw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_and_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'goodforairplane'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m74\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvisuals_selected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLVW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlvw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisuals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'goodforairplane'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m74\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\Experimental_Design_for_Data_Science\\LVW.py\u001b[0m in \u001b[0;36mlvw\u001b[1;34m(data, target, n, gamma, max_tries, random_state)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mc_best\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mincon_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                 \u001b[0ms_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mc_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\Experimental_Design_for_Data_Science\\LVW.py\u001b[0m in \u001b[0;36mincon_check\u001b[1;34m(data, target)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mequal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                     \u001b[0mequal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mequal\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Experimental_Design_for_Data_Science\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1412\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1413\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1414\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1415\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Experimental_Design_for_Data_Science\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_is_scalar_access\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2051\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2053\u001b[1;33m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2054\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Experimental_Design_for_Data_Science\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36maxes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m         dtype='object')]\n\u001b[0;32m    505\u001b[0m         \"\"\"\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "import LVW\n",
    "\n",
    "metadata_selected_features = LVW.lvw(metadata[0:95],movies[0:95].loc[:,'goodforairplane'],0.)\n",
    "visuals_selected_features = LVW.lvw(visuals[0:95],movies[0:95].loc[:,'goodforairplane'],0.)\n",
    "audio_selected_features = LVW.lvw(audio[0:95],movies[0:95].loc[:,'goodforairplane'],0.)\n",
    "text_selected_features = LVW.lvw(text[0:95],movies[0:95].loc[:,'goodforairplane'],0.)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meta_algo_pool = [knn,nc,tree,log,svm,bag,rf,ada,gb]\n",
    "text_algo_pool = [gauss,knn,svm]\n",
    "visual_algo_pool = [knn,tree,log,svm,rf,ada,gb]\n",
    "audio_algo_pool = [log,gb]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in meta_algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=metadata[0:95].loc[metadata_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=metadata[0:95].loc[metadata_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=metadata[0:95].loc[metadata_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in visual_algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=visuals[0:95].loc[visuals_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=visuals[0:95].loc[visuals_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=visuals[0:95].loc[visuals_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in audio_algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=audio[0:95].loc[audio_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=audio[0:95].loc[audio_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=audio[0:95].loc[audio_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in text_algo_pool:\n",
    "    f1 = np.mean(cross_val_score(estimator=i,X=text[0:95].loc[text_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='f1',cv=10,n_jobs=-1))\n",
    "    precision = np.mean(cross_val_score(estimator=i,X=text[0:95].loc[text_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='precision',cv=10,n_jobs=-1))\n",
    "    recall = np.mean(cross_val_score(estimator=i,X=text[0:95].loc[text_selected_features],y=movies[0:95].loc[:,'goodforairplane'],\n",
    "                         scoring='recall',cv=10,n_jobs=-1))\n",
    "    print(str(i).split('(')[0])\n",
    "    print(f'Precision: {precision}, Recall: {recall}, f1: {f1}')\n",
    "    print()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_meta = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski',\n",
    "                           metric_params=None,n_jobs=-1)\n",
    "\n",
    "nc_meta = NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
    "\n",
    "tree_meta = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                              min_weight_fraction_leaf=0.0, max_features=None, random_state=0, max_leaf_nodes=None,\n",
    "                              class_weight=None, presort=False)\n",
    "\n",
    "log_meta = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1,\n",
    "                         class_weight=None, random_state=0, solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "\n",
    "svm_meta = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "          cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=0)\n",
    "\n",
    "bag_meta = BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "                        bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=-1, random_state=0, verbose=0)\n",
    "\n",
    "rf_meta = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, \n",
    "                            oob_score=False, n_jobs=-1, random_state=0, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "ada_meta = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=0)\n",
    "\n",
    "gb_meta = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, random_state=0,\n",
    "                                max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "\n",
    "gauss_text = GaussianNB()\n",
    "\n",
    "knn_text = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski',\n",
    "                           metric_params=None,n_jobs=-1)\n",
    "\n",
    "svm_text = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "          cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=0)\n",
    "\n",
    "knn_vis = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski',\n",
    "                           metric_params=None,n_jobs=-1)\n",
    "\n",
    "tree_vis = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "                              min_weight_fraction_leaf=0.0, max_features=None, random_state=0, max_leaf_nodes=None,\n",
    "                              class_weight=None, presort=False)\n",
    "\n",
    "log_vis = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1,\n",
    "                         class_weight=None, random_state=0, solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "\n",
    "svm_vis = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, \n",
    "          cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=0)\n",
    "\n",
    "rf_vis = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                            min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, bootstrap=True, \n",
    "                            oob_score=False, n_jobs=-1, random_state=0, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "ada_vis = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=0)\n",
    "\n",
    "gb_vis = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, random_state=0,\n",
    "                                max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "\n",
    "log_audio = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1,\n",
    "                         class_weight=None, random_state=0, solver='liblinear', max_iter=100, multi_class='ovr', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "\n",
    "gb_audio = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, min_samples_split=2,\n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, init=None, random_state=0,\n",
    "                                max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "\n",
    "estimators = [('knn_meta',knn_meta),('nc_meta',nc_meta),('tree_meta',tree_meta),('log_meta',log_meta),('svm_meta',svm_meta),\n",
    "              ('bag_meta',bag_meta),('rf_meta',rf_meta),('ada_meta',ada_meta),('gb_meta',gb_meta),('gauss_text',gauss_text),\n",
    "              ('knn_text',knn_text),('svm_text',svm_text),('knn_vis',knn_vis),('tree_vis',tree_vis),('log_vis',log_vis),\n",
    "              ('svm_vis',svm_vis),('rf_vis',rf_vis),('ada_vis',ada_vis),('gb_vis',gb_vis),('log_audio',log_audio),('gb_audio',gb_audio)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from stacking_classifiers import stacking_classifier_performance_cv\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    res = stacking_classifier_performance_cv(estimators,metadata[0:95].loc[metadata_selected_features],visuals[0:95].loc[visuals_selected_features],text[0:95].loc[text_selected_features],audio[0:95].loc[audio_selected_features],movies[0:95].loc[:,'goodforairplane'])\n",
    "    print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from stacking_classifiers import stacking_classifier_performance_on_test_set\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    res = stacking_classifier_performance_on_test_set(estimators,metadata.loc[metadata_selected_features],visuals.loc[visuals_selected_features],text.loc[text_selected_features],audio.loc[audio_selected_features],movies.loc[:,'goodforairplane'],95)\n",
    "    print(res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}